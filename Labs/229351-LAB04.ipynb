{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "rUWDxJYaXbGS"
   },
   "source": [
    "ปฏิบัติการครั้งที่ 4 กระบวนวิชา 229351 Statistical Learning for Data Science\n",
    "\n",
    "คำชี้แจง\n",
    "\n",
    "1. ให้เริ่มทำปฏิบัติการจาก colab notebook ที่กำหนดให้ จากนั้นบันทึกเป็นไฟล์ *.ipynb (File -> Download .ipynb)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "LfrNe5MdqS2b"
   },
   "source": [
    "#Task 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "OYdg96RVZEJg"
   },
   "source": [
    "# Empirical risk for virus testing\n",
    "\n",
    "ในปัญหานี้เราจะทำการศึกษาการสร้างวิธีในการจำแนกคนที่เป็นโรคไวรัสจากการทดสอบชนิดหนึ่ง \n",
    "\n",
    "กำหนดให้ $R$ (reality) เป็นเหตุการณ์ที่คน $N$ คนเป็นหรือไม่เป็นพาหะนำโรคชนิดนี้\n",
    "\n",
    "`reality = [r1,r2,...,rN]`\n",
    "\n",
    "โดยที่ผลจากการทดสอบจะบอกถึงโอกาส (probability) ที่คนๆหนึ่งเป็นพาหะของโรคนี้\n",
    "\n",
    "`p = [p1,p2,...,pN]`\n",
    "\n",
    "โดยที่เราจะเป็นคนกำหนดค่า threshold $\\alpha$ ที่บอกว่า\n",
    "\n",
    "* ถ้า `pi` $>\\alpha$ แสดงว่าคนที่ `i` **เป็น**พาหะของโรคนี้\n",
    "* ถ้า `pi` $\\leq\\alpha$ แสดงว่าคนที่ `i` **ไม่เป็น**พาหะของโรคนี้\n",
    "\n",
    "กำหนดให้ $D$ (decision) เป็นการตัดสินใจที่ตามมา\n",
    "\n",
    "`decisions = [d1,d2,...,dN]`\n",
    "\n",
    "สมมติว่าเรากำหนดให้ความเสียหายจาก **false negative** (reality = 1 แต่ decision = 0) มีค่าเป็น $k$ เท่าของความเสียหายจาก **false positive** (reality = 0 แต่ decision = 1) loss function ที่ได้คือ (ค่า k กำหนดทีหลัง)\n",
    "\n",
    "$$\\begin{cases} \\mathcal{l}(di=1,ri=0) = 1\\\\\n",
    "\\mathcal{l}(di=0,ri=1) = k\\\\\n",
    "\\mathcal{l}(di=0,ri=0)=\\mathcal{l}(di=1,ri=1) = 0\\end{cases}$$\n",
    "\n",
    "ดังนั้น empirical risk function ที่ได้คือ\n",
    "\n",
    "$$R = \\frac{1}{N}\\sum_{i=1}^N l(di,ri)$$\n",
    "\n",
    "นั่นคือ เราสามารถคำนวณ $R$ ได้ด้วยการบวก loss ของการทดสอบที่ผิดพลาดทั้งหมด แล้วหารด้วยจำนวณการทดสอบทั้งหมด"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "m9fVbQV4nO6U"
   },
   "source": [
    "สร้างข้อมูลจำลองด้วยโค้ดข้างล่างนี้"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "wyB_40PZgOWN"
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "from scipy.stats import norm\n",
    "\n",
    "# Note: don't make any changes to this function\n",
    "def generate_ground_truth(N, prevalence):\n",
    "    \"\"\" สร้างข้อมูลจำลอง\"\"\"\n",
    "    rs = np.random.RandomState(1)\n",
    "    reality = rs.binomial(1, prevalence, N)\n",
    "    p = norm.cdf(rs.randn(N) + reality)\n",
    "    return(p, reality)\n",
    "\n",
    "# Generate p: Do not modify\n",
    "N = 10000\n",
    "prevalence = 0.05\n",
    "p, reality = generate_ground_truth(N, prevalence)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "8TaQ2YeT3MKQ"
   },
   "outputs": [],
   "source": [
    "p"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "U7HWVnEQ3RN3"
   },
   "outputs": [],
   "source": [
    "reality"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "bDPHaracnWaC"
   },
   "source": [
    "ฟังก์ชัน `alpha_threshold_decisions` ใช้ในการตัดสินใจว่าแต่ละคนเป็นหรือไม่เป็นพาหะ (`decisions`)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "SIraC0aMhESF"
   },
   "outputs": [],
   "source": [
    "# Note: don't make any changes to this function, this is exatly the naive thresholding you completed in Lab 1\n",
    "def alpha_threshold_decisions(p, alpha):\n",
    "    \"\"\"\n",
    "    Returns decisions on p using naive thresholding.\n",
    "    \n",
    "    Inputs:\n",
    "        p: array p[i] คือความน่าจะเป็นที่ตัวอย่างที่ i มีเชื้อไวรัส\n",
    "        alpha: threshold: p > alpha ถือว่าเป็น p <= alpha ถือว่าไม่เป็น\n",
    "    \n",
    "    Returns:\n",
    "        decisions: `decisions[i]=1` ถือว่าเป็น \n",
    "        `decisions[i]=0` ถือว่าไม่เป็น\n",
    "    \"\"\"\n",
    "    decisions = p > alpha\n",
    "    return decisions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "kZKeLMdz3f8z"
   },
   "outputs": [],
   "source": [
    "alpha_threshold_decisions(np.array([0.2,0.8]), alpha=0.7)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "bhdRa_aEntbk"
   },
   "source": [
    "ฟังก์ชัน `report_results` ใช้ในการคำนวณว่าการตัดสินใจถูกหรือผิดอย่างไรบ้าง\n",
    "\n",
    "* TP (true positive): `ri`=1,`di`=1 \n",
    "* TN (true negative): `ri`=0,`di`=0 \n",
    "* FP (false positive): `ri`=0,`di`=1 \n",
    "* FN (false negative): `ri`=1,`di`=0 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "JqBep_Rxgw8f"
   },
   "outputs": [],
   "source": [
    "# Note: don't make any changes to this function, this is the report_results function you completed in Lab 1\n",
    "def report_results(decisions, reality):\n",
    "    \"\"\"\n",
    "    สร้าง dictionary ที่ประกอบไปด้วยจำนวนตัวอย่างในกลุ่ม true positives, \n",
    "    true negatives, false negatives, และ false positives \n",
    "    จากการตัดสินใจด้วย `alpha_threshold_decisions`\n",
    "    \n",
    "    Inputs:\n",
    "      decisions: array ที่มีค่า 0/1, decisions[i] =1 ถ้าการทดสอบบอกว่าคนที่ i มีเชื้อไวรัส\n",
    "      reality: array ที่มีค่า 0/1, reality[i] =1 ถ้าคนที่ i มีเชื้อไวรัสจริง\n",
    "    \n",
    "    Outputs: dictionary ที่ประกอบไปด้วยค่า TN, TP, FN, และ FP \n",
    "    \"\"\"   \n",
    "    \n",
    "    TP_count = sum(decisions*reality)\n",
    "    TN_count = sum((1-decisions)*(1-reality))\n",
    "    FP_count = sum((decisions)*(1-reality))\n",
    "    FN_count = sum((1-decisions)*(reality))\n",
    "    \n",
    "    results_dictionary = {\"TN_count\": TN_count,\n",
    "                          \"TP_count\": TP_count,\n",
    "                          \"FN_count\": FN_count,\n",
    "                          \"FP_count\": FP_count,\n",
    "                         }\n",
    "    return results_dictionary"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "pFGkK_jb_GW7"
   },
   "source": [
    "`results_dictionary[\"FP_count\"]`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "O91j2pHelLaf"
   },
   "source": [
    "### Exercise 1a: เติมฟังก์ชันเพื่อคำนวณ empirical risk จากค่าจำนวนความถูกต้องและจำนวนความผิดพลาด (TP, FP, TN, FN) ที่บันทึกใน `results_dictionary` โดยที่ `factor_k` คือค่า $k$ ที่ระบุในนิยามของ loss function ข้างบน"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "5MPj5z6luEKy"
   },
   "source": [
    "#### Loss function คือ\n",
    "\n",
    "$$\\begin{cases} \\mathcal{l}(di=1,ri=0) = 1\\\\\n",
    "\\mathcal{l}(di=0,ri=1) = k\\\\\n",
    "\\mathcal{l}(di=0,ri=0)=\\mathcal{l}(di=1,ri=1) = 0\\end{cases}$$\n",
    "\n",
    "#### Empirical risk function คือ\n",
    "\n",
    "$$R = \\frac{1}{N}\\sum_{i=1}^N l(di,ri)$$\n",
    "\n",
    "นั่นคือ เราสามารถคำนวณ $R$ ได้ด้วยการบวก loss ของการทดสอบที่ผิดพลาดทั้งหมด แล้วหารด้วยจำนวณการทดสอบทั้งหมด"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "fdLeqno7hAKG"
   },
   "outputs": [],
   "source": [
    "# TODO: fill in\n",
    "def compute_empirical_risk(results_dictionary, factor_k):\n",
    "    \"\"\" คำนวณ empirical risk ด้วยค่า TP, FP, TN และ FN ใน results_dictionary\n",
    "        โดยที่ค่าของ false positive คือ 1\n",
    "        และค่าของ false negative คือ k\n",
    "        \n",
    "        Inputs:\n",
    "            results_dictionary : dictionary ที่มีค่า TP, FP, TN และ FN\n",
    "            factor_k : ค่า loss ของแต่ละตัวอย่างที่อยู่ในกลุ่ม false negative\n",
    "                       \n",
    "        Outputs:\n",
    "            empirical_risk : float\n",
    "    \"\"\"\n",
    "    \n",
    "    TP_count = results_dictionary['TP_count']\n",
    "    FP_count = results_dictionary['FP_count'] #แต่ละคนได้ค่า loss = 1\n",
    "    TN_count = results_dictionary['TN_count']\n",
    "    FN_count = results_dictionary['FN_count'] #แต่ละคนได้ค่า loss = k\n",
    "    \n",
    "    N = TP_count + TN_count + FP_count + FN_count\n",
    "    empirical_risk = 1/N * (factor_k*FN_count + FP_count) # TODO: fill in\n",
    "    return(empirical_risk)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "u0zrvphnzUSp"
   },
   "outputs": [],
   "source": [
    "res_dict = {'TP_count': 100, 'FP_count': 20, 'TN_count':450, 'FN_count':30}\n",
    "k_factors = [0, 10, 100]\n",
    "for i, k in enumerate(k_factors):\n",
    "    empirical_risk = compute_empirical_risk(res_dict, k)\n",
    "    print(empirical_risk)\n",
    "\n",
    "#Answers should be: \n",
    "# 0.03333333333333333\n",
    "# 0.5333333333333333\n",
    "# 5.033333333333333"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "m85aCRvFmCto"
   },
   "source": [
    "### Exercise 1b: เติมฟังก์ชันเพื่อคำนวณ empirical risk โดยที่มี argument ดังนี้ \n",
    "\n",
    "* `reality` การเป็นพาหะจริง  \n",
    "* `p` ความน่าจะเป็นที่ได้จากการทดสอบ \n",
    "* `alpha` ค่า threshold ในการตัดสินใจว่าแต่ละคนเป็นพาหะหรือไม่\n",
    "* `factor_k` คือค่า $k$ ที่ระบุในนิยามของ loss function ข้างบน"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "nKW44BX2f-0-"
   },
   "outputs": [],
   "source": [
    "# TODO: complete the function\n",
    "def compute_alpha_empirical_risk(p, reality, alpha, factor_k):\n",
    "    \"\"\" \n",
    "    คำนวณค่า empirical risk ที่ค่า threshold alpha\n",
    "    \n",
    "    Inputs:\n",
    "        p: array of floats, p[i] คือความน่าจะเป็นที่ตัวอย่างที่ i มีเชื้อไวรัส\n",
    "        reality: array ที่มีค่า 0/1, reality[i] =1 ถ้าคนที่ i มีเชื้อไวรัสจริง\n",
    "        alpha: float, threshold สำหรับการตัวสินใจว่าแต่ละคนมีเชื้อไวรัสหรือไม่\n",
    "        factor_k: float, ค่า loss ของแต่ละตัวอย่างที่อยู่ในกลุ่ม false negative\n",
    "                  \n",
    "    Outputs:\n",
    "        empirical_risk: float, empirical risk\n",
    "    \"\"\"\n",
    "\n",
    "    #From p, alpha return decisions\n",
    "    decisions = alpha_threshold_decisions(p, alpha)\n",
    "    #From reality and decisions, return a dictionary of TP, FP, TN ,FN\n",
    "    results_dictionary = report_results(decisions, reality)\n",
    "    #From the dictionary and factor_k, compute the empirical risk\n",
    "    empirical_risk = compute_empirical_risk(results_dictionary, factor_k)\n",
    "    return empirical_risk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "NC4jRO4Rz8pk"
   },
   "outputs": [],
   "source": [
    "print('At level alpha=', 0.05 ,' and k=', 0 ,' the average loss is', \\\n",
    "      compute_alpha_empirical_risk(p, reality,0.05,0))\n",
    "print('At level alpha=', 0.05 ,' and k=', 10 ,' the average loss is', \\\n",
    "      compute_alpha_empirical_risk(p, reality,0.05,10))\n",
    "print('At level alpha=', 0.05 ,' and k=', 100 ,' the average loss is', \\\n",
    "      compute_alpha_empirical_risk(p, reality,0.05,100))\n",
    "\n",
    "#Answers should be 0.0499, 0.3909, 3.4599\n",
    "#Answers should be 0.9032, 1.0312, 2.1832"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "oUdNjhX3hewV"
   },
   "outputs": [],
   "source": [
    "# Run this as is after completing the `compute_alpha_empirical_risk` function\n",
    "# Do not modify\n",
    "def plot_empirical_risk(factor_k):\n",
    "    N = 10000\n",
    "    # generate ground truth\n",
    "    p, reality = generate_ground_truth(N, 0.05)\n",
    "    # vary alpha from 0 to 1\n",
    "    alpha_array = np.arange(0,1, 0.05)\n",
    "    # compute average loss for each alpha\n",
    "    empirical_risk_array = [compute_alpha_empirical_risk(p, reality, alpha, factor_k) for alpha in alpha_array]\n",
    "    optimal_alpha = alpha_array[np.argmin(empirical_risk_array)]\n",
    "    plt.figure(figsize=(10, 6))\n",
    "    plt.plot(alpha_array, empirical_risk_array, label = 'Average Loss')\n",
    "    plt.axvline(x=optimal_alpha, ls='--', label = 'Optimal $\\\\alpha$', c='green')\n",
    "    plt.xlabel('$\\\\alpha$ level')\n",
    "    plt.ylabel('Average Loss')\n",
    "    plt.legend()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "PjGQ20wxh_cZ"
   },
   "outputs": [],
   "source": [
    "from ipywidgets import interact, interactive\n",
    "\n",
    "# Visualize interactive plot: Do not modify\n",
    "interactive_plot = interactive(plot_empirical_risk, factor_k=(0, 100, 5))\n",
    "interactive_plot"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "AbgAEXI3jdgr"
   },
   "source": [
    "### Exercise 1c: factor_k กับค่า $\\alpha$ ที่ดีทีสุด (Optimal $\\alpha$) มีความสัมพันธ์กันอย่างไร"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "eZnDbI1HkAeh"
   },
   "source": [
    "คำตอบ:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "UU6M_cw-qPMY"
   },
   "source": [
    "#Task 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Y3XRvN5ottw3"
   },
   "source": [
    "###Sample points"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "_mP9iX86slv6"
   },
   "outputs": [],
   "source": [
    "np.random.seed(42)\n",
    "\n",
    "N = 8\n",
    "x = 10 ** np.linspace(-2, 0, N)\n",
    "y = np.random.normal(loc = 10 - 1. / (x + 0.1), scale= 0.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "YGZGigLcs6aQ"
   },
   "outputs": [],
   "source": [
    "plt.figure()\n",
    "plt.scatter(x, y, c='k')\n",
    "plt.xlabel('x')\n",
    "plt.ylabel('y')\n",
    "plt.title('Sample points');"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "QdZi8kpttrKV"
   },
   "source": [
    "### Polynomial regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "6FniOUFStYfh"
   },
   "outputs": [],
   "source": [
    "p = np.polyfit(x, y, 2)\n",
    "\n",
    "\n",
    "xfit = np.linspace(-0.2, 1.2, 1000)\n",
    "yfit = np.polyval(p, xfit)\n",
    "\n",
    "p"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "dkwag247tVkn"
   },
   "outputs": [],
   "source": [
    "plt.figure()\n",
    "plt.scatter(x, y, marker='x', c='k', s=50)\n",
    "plt.plot(xfit, yfit, '-b')\n",
    "plt.xlabel('x')\n",
    "plt.ylabel('y')\n",
    "plt.title('d = 2')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "2R56DzSxsZnG"
   },
   "outputs": [],
   "source": [
    "xfit = np.linspace(-0.2, 1.2, 1000)\n",
    "\n",
    "titles = ['d = 1 (under-fit)', 'd = 2', 'd = 6 (over-fit)']\n",
    "degrees = [1, 2, 6]\n",
    "\n",
    "plt.figure(figsize = (9, 3.5))\n",
    "for i, d in enumerate(degrees):\n",
    "    plt.subplot(131 + i, xticks=[], yticks=[])\n",
    "    plt.scatter(x, y, marker='x', c='k', s=50)\n",
    "\n",
    "    p = np.polyfit(x, y, d)\n",
    "    yfit = np.polyval(p, xfit)\n",
    "    plt.plot(xfit, yfit, '-b')\n",
    "    \n",
    "    plt.xlim(-0.2, 1.2)\n",
    "    plt.ylim(0, 12)\n",
    "    plt.xlabel('x')\n",
    "    if i == 0:\n",
    "        plt.ylabel('y')\n",
    "\n",
    "    plt.title(titles[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "W4mkSzTBalJi"
   },
   "outputs": [],
   "source": [
    "np.random.seed(42)\n",
    "\n",
    "Ntrain = 20\n",
    "Ntest = 20\n",
    "error = 1.0\n",
    "\n",
    "np.random.seed(0)\n",
    "x = np.random.random(Ntrain + Ntest)\n",
    "y = np.random.normal(loc = 10 - 1. / (x + 0.1), scale= 0.5)\n",
    "\n",
    "xtrain = x[:Ntrain]\n",
    "ytrain = y[:Ntrain]\n",
    "\n",
    "xtest = x[Ntrain:]\n",
    "ytest = y[Ntrain:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "wVuM72Utrd8n"
   },
   "outputs": [],
   "source": [
    "plt.scatter(xtrain, ytrain, c='k')\n",
    "plt.xlabel('x')\n",
    "plt.ylabel('y')\n",
    "plt.title('Training set');"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "58vJUL9mP-Qs"
   },
   "outputs": [],
   "source": [
    "plt.scatter(xtest, ytest, c='k')\n",
    "plt.xlabel('x')\n",
    "plt.ylabel('y')\n",
    "plt.title('Test set');"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "TvPb79u0wHTz"
   },
   "source": [
    "#### ในกรณีนี้ เราใช้ squared-loss ดังนั้น empirical risk เท่ากับ MSE (mean-squared error) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "gUX3YRrOusyc"
   },
   "outputs": [],
   "source": [
    "def empirical_risk(y, yfit):\n",
    "    return np.mean((y - yfit) ** 2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "XmqhAOtfvF16"
   },
   "source": [
    "# Exercise 2: \n",
    "1. ทำการสร้าง polynomial regression ที่มีค่า degree ตั้งแต่ 1-10 โดยใช้ training set ข้างบน \n",
    "2. หลังจากสร้างโมเดลแต่ละตัวเสร็จแล้ว ให้คำนวณค่า empirical risk ของการทำนายบน test set เก็บค่าที่ได้ไว้ใน list ที่ชื่อว่า `empirical_risks` (เพราะฉะนั้น list นี้จะมีสมาชิก 10 ตัว)\n",
    "3. สร้าง plot โดยให้แกนนอนคือค่า degree ของโมเดลแต่ละตัว และแกนตั้งคือค่า empirical risk ของโมเดลตัวนั้น \n",
    "4. ระบุค่า degree ที่มี empirical risk ต่ำที่สุด\n",
    "ค่า degree ไหนบ้างที่ทำให้โมเดล overfit และค่า degree ไหนบ้างที่ทำให้โมเดล underfit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "RSuwcM2cxnrT"
   },
   "outputs": [],
   "source": [
    "max_degree = 10\n",
    "\n",
    "empirical_risks = [0]*max_degree\n",
    "\n",
    "for d in range(1,max_degree+1):\n",
    "  #TODO: fill code here\n",
    "  p = np.polyfit(xtrain, ytrain, d)\n",
    "  ypred = np.polyval(p, xtest)\n",
    "  r = empirical_risk(ytest, ypred)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "mo0hPYFxHJCa"
   },
   "outputs": [],
   "source": [
    "p = np.polyfit(xtrain, ytrain, 6)\n",
    "\n",
    "plt.figure()\n",
    "\n",
    "plt.scatter(xtest, ytest)\n",
    "xfit2 = np.linspace(0, 1.1, 1000)\n",
    "plt.plot(xfit2, np.polyval(p, xfit2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "HiDKHu__MvWh"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "229351-LAB04.ipynb",
   "provenance": [
    {
     "file_id": "1k58-rg4oQW3wpRV4o0QKkjNuoDH4G6JK",
     "timestamp": 1576730343500
    }
   ]
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
